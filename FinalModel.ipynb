{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all data for different data sets\n",
    "\n",
    "train_df = pd.read_csv('Description_Day_Quantity.csv')\n",
    "\n",
    "train_df_customers = pd.read_csv('Customer_Description_Day_Quantity.csv')\n",
    "\n",
    "train_df_NoDesc = pd.read_csv('Customer_Day_Quantity.csv')\n",
    "\n",
    "test_data1 = pd.read_csv('Test_df_use.csv')\n",
    "test_df_org = test_data1.copy()\n",
    "\n",
    "train_df_DescQuantDays = train_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1.head()\n",
    "\n",
    "#var_list = [\\\n",
    "#       'Quantity_Median', 'Quantity_Max', 'Quantity_Min', 'Quantity_StDev'\\\n",
    "#           ]\n",
    "\n",
    "#var_list = ['Price_MeanDesc', 'Price_MedianDesc',\n",
    "#       'Price_MaxDesc', 'Price_MinDesc', 'Price_StDevDesc',\n",
    "#       'Price_Mean_Customer', 'Price_StDev_Customer', 'Quantity_Mean',\n",
    "#       'Quantity_Median', 'Quantity_Max', 'Quantity_Min', 'Quantity_StDev',\n",
    "#       'Price_Mode1']\n",
    "\n",
    "var_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3789\n",
      "3563\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "#Divide test dataset in two parts with Description in train and without Description in train\n",
    "description_list_train = list(train_df_DescQuantDays['Description'].drop_duplicates())\n",
    "description_list_test = list(test_data1['Description'].drop_duplicates())\n",
    "\n",
    "print(len(description_list_train))\n",
    "print(len(description_list_test))\n",
    "\n",
    "description_list_test_only = (set(description_list_test) - set(description_list_train))\n",
    "\n",
    "print(len(description_list_test_only))\n",
    "\n",
    "test_data_unique_desc = test_data1[test_data1['Description'].isin(description_list_test_only)]\n",
    "test_data_rep_desc = test_data1[~test_data1['Description'].isin(description_list_test_only)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting Index\n",
    "\n",
    "test_data_unique_desc.index = range(len(test_data_unique_desc))\n",
    "test_data_rep_desc.index = range(len(test_data_rep_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Country35</th>\n",
       "      <th>days_since_first_sold</th>\n",
       "      <th>Price_Mode_Sum</th>\n",
       "      <th>Price_MeanDesc</th>\n",
       "      <th>Price_MedianDesc</th>\n",
       "      <th>Price_MaxDesc</th>\n",
       "      <th>Price_MinDesc</th>\n",
       "      <th>Price_StDevDesc</th>\n",
       "      <th>Price_Mean_Customer</th>\n",
       "      <th>Price_StDev_Customer</th>\n",
       "      <th>Quantity_Mean</th>\n",
       "      <th>Quantity_Median</th>\n",
       "      <th>Quantity_Max</th>\n",
       "      <th>Quantity_Min</th>\n",
       "      <th>Quantity_StDev</th>\n",
       "      <th>Price_Mode1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16161</td>\n",
       "      <td>1079</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.364909</td>\n",
       "      <td>3.475940</td>\n",
       "      <td>7.684211</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>9.389774</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17341</td>\n",
       "      <td>3457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.193421</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.272806</td>\n",
       "      <td>2.082536</td>\n",
       "      <td>1.563595</td>\n",
       "      <td>5.527273</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>5.776243</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15158</td>\n",
       "      <td>694</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "      <td>7.70</td>\n",
       "      <td>3.871658</td>\n",
       "      <td>4.25</td>\n",
       "      <td>7.46</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.489634</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.376554</td>\n",
       "      <td>5.258389</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>7.243505</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16033</td>\n",
       "      <td>3473</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>206</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.642658</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.261951</td>\n",
       "      <td>3.418571</td>\n",
       "      <td>2.832470</td>\n",
       "      <td>11.314779</td>\n",
       "      <td>12.0</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>15.310779</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15351</td>\n",
       "      <td>871</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>23.70</td>\n",
       "      <td>12.654669</td>\n",
       "      <td>12.75</td>\n",
       "      <td>24.96</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.863610</td>\n",
       "      <td>2.833780</td>\n",
       "      <td>2.262824</td>\n",
       "      <td>3.704104</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>10.071870</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Description  Quantity  Country35  days_since_first_sold  \\\n",
       "0       16161         1079         3          1                     72   \n",
       "1       17341         3457         1          1                      6   \n",
       "2       15158          694        36          1                    328   \n",
       "3       16033         3473         2          1                    206   \n",
       "4       15351          871         1          1                    339   \n",
       "\n",
       "   Price_Mode_Sum  Price_MeanDesc  Price_MedianDesc  Price_MaxDesc  \\\n",
       "0            3.30        1.650000              1.65           1.65   \n",
       "1            2.08        1.193421              1.25           2.46   \n",
       "2            7.70        3.871658              4.25           7.46   \n",
       "3            3.10        1.642658              1.65           3.29   \n",
       "4           23.70       12.654669             12.75          24.96   \n",
       "\n",
       "   Price_MinDesc  Price_StDevDesc  Price_Mean_Customer  Price_StDev_Customer  \\\n",
       "0           1.65         0.000000             3.364909              3.475940   \n",
       "1           0.83         0.272806             2.082536              1.563595   \n",
       "2           2.95         0.489634             1.820000              1.376554   \n",
       "3           1.25         0.261951             3.418571              2.832470   \n",
       "4           8.12         0.863610             2.833780              2.262824   \n",
       "\n",
       "   Quantity_Mean  Quantity_Median  Quantity_Max  Quantity_Min  Quantity_StDev  \\\n",
       "0       7.684211              6.0            48             1        9.389774   \n",
       "1       5.527273              3.0            24             1        5.776243   \n",
       "2       5.258389              4.0            36             1        7.243505   \n",
       "3      11.314779             12.0           192             1       15.310779   \n",
       "4       3.704104              2.0           160             1       10.071870   \n",
       "\n",
       "   Price_Mode1  \n",
       "0         1.65  \n",
       "1         1.25  \n",
       "2         4.25  \n",
       "3         1.65  \n",
       "4        12.75  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_DescQuantDays.head()\n",
    "test_data_rep_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Regression\n",
    "\n",
    "def MultipleLinearRegression_Regressor(train_df):\n",
    "    # Importing the dataset\n",
    "    dataset = train_df.copy()\n",
    "    #print(len(dataset))\n",
    "\n",
    "    X_train = dataset.iloc[:, :-1].values\n",
    "    y_train = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Training the Multiple Linear Regression model on the Training set\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "     # Predicting the Test set results\n",
    "    y_pred = regressor.predict(X_train)\n",
    "    #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train.reshape(len(y_train),1)),1))\n",
    "\n",
    "    # Evaluating the Model Performance\n",
    "    rscore = r2_score(y_train, y_pred)\n",
    "    rmse_score = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    # Evaluate the models using crossvalidation\n",
    "    if(len(X_train)>1):\n",
    "        scores = cross_val_score(regressor, X_train, y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=min(10,len(X_train)))\n",
    "    else:\n",
    "        scores = np.array([0])\n",
    "        \n",
    "    #print(\"MSE = {:.2e}(+/- {:.2e})\".format(-scores.mean(), scores.std()))\n",
    "    return regressor,rmse_score,-scores.mean(),scores.std(), rscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "def DecisionTreeClassification_Regressor(train_df):\n",
    "    # Importing the dataset\n",
    "    dataset = train_df.copy()\n",
    "    #print(len(dataset))\n",
    "    \n",
    "    dataset['UnitPrice'] = dataset['UnitPrice'].astype(str)\n",
    "    X_train = dataset.iloc[:, :-1].values\n",
    "    y_train = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Training the Decision Tree Regression model on the Training set\n",
    "    # regressor = DecisionTreeRegressor(max_depth = 9, random_state = 0)\n",
    "    #regressor = DecisionTreeRegressor(min_samples_leaf = 2, max_depth = 10, random_state = 0)\n",
    "    regressor = DecisionTreeClassifier(max_depth = 7, random_state = 42)\n",
    "    #regressor = DecisionTreeRegressor(max_depth = 7, random_state = 42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regressor.predict(X_train)\n",
    "    #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train.reshape(len(y_train),1)),1))\n",
    "\n",
    "    # Evaluating the Model Performance\n",
    "    rscore = r2_score(y_train, y_pred)\n",
    "    rmse_score = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    len_uniq = len(dataset['UnitPrice'].unique())\n",
    "    \n",
    "    # Evaluate the models using crossvalidation\n",
    "    #if(len(X_train)>1) and len_uniq>1 and len(X_train)> len_uniq:\n",
    "    #    scores = cross_val_score(regressor, X_train, y_train,\n",
    "    #                         scoring=\"neg_mean_squared_error\", cv=min(10,len(X_train)))\n",
    "    #else:\n",
    "    scores = np.array([0])\n",
    "        \n",
    "    #print(\"MSE = {:.2e}(+/- {:.2e})\".format(-scores.mean(), scores.std()))\n",
    "    return regressor,rmse_score,-scores.mean(),scores.std(), rscore, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "def DecisionTreeRegression_Regressor(train_df):\n",
    "    # Importing the dataset\n",
    "    dataset = train_df.copy()\n",
    "    #print(len(dataset))\n",
    "\n",
    "    X_train = dataset.iloc[:, :-1].values\n",
    "    y_train = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Training the Decision Tree Regression model on the Training set\n",
    "    # regressor = DecisionTreeRegressor(max_depth = 9, random_state = 0)\n",
    "    #regressor = DecisionTreeRegressor(min_samples_leaf = 2, max_depth = 10, random_state = 0)\n",
    "    #regressor = DecisionTreeClassifier()\n",
    "    regressor = DecisionTreeRegressor(max_depth = 7, random_state = 42)\n",
    "    \n",
    "    \n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regressor.predict(X_train)\n",
    "    #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train.reshape(len(y_train),1)),1))\n",
    "\n",
    "    # Evaluating the Model Performance\n",
    "    rscore = r2_score(y_train, y_pred)\n",
    "    rmse_score = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "     # Evaluate the models using crossvalidation\n",
    "    if(len(X_train)>1):\n",
    "        scores = cross_val_score(regressor, X_train, y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=min(10,len(X_train)))\n",
    "    else:\n",
    "        scores = np.array([0])\n",
    "        \n",
    "    #print(\"MSE = {:.2e}(+/- {:.2e})\".format(-scores.mean(), scores.std()))\n",
    "    return regressor,rmse_score,-scores.mean(),scores.std(), rscore, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR Regressor\n",
    "\n",
    "parameters = [{'C':[0.25, 0.5, 0.75, 1], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\\\n",
    "              'epsilon':[0.1, 0.3 , 0.5]}]\n",
    "\n",
    "def SVR_Regressor(train_df):\n",
    "    # Importing the dataset\n",
    "    dataset = train_df.copy()\n",
    "    #print(len(dataset))\n",
    "\n",
    "    X_train = dataset.iloc[:, :-1].values\n",
    "    y_train = dataset.iloc[:, -1].values\n",
    "    y_train = y_train.reshape(len(y_train),1)\n",
    "\n",
    "    # Feature Scaling\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    y_train = sc_y.fit_transform(y_train)\n",
    "    \n",
    "    \"\"\"if(len(X_train)>1):\n",
    "        # Gridsearch to get best regressor\n",
    "        grid_search = GridSearchCV(estimator = SVR(), param_grid = parameters, scoring = 'neg_mean_squared_error',\\\n",
    "                                  cv = min(10,len(X_train)), n_jobs = -1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_sc = grid_search.best_score_\n",
    "        best_param = grid_search.best_params_\n",
    "        regressor = SVR(C = best_param['C'], epsilon = best_param['epsilon'], kernel = best_param['kernel'],\\\n",
    "                        gamma = best_param['gamma'])\n",
    "        \n",
    "    else:\"\"\"\n",
    "    best_sc = ''\n",
    "    best_param = ''\n",
    "    #regressor = SVR()\n",
    "    \n",
    "    # Training the SVR model on the Training set    \n",
    "    #regressor = SVR(C=1, epsilon=0.1, kernel = 'rbf')\n",
    "    regressor = SVR(C=0.5, epsilon=0.3, kernel = 'linear')\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X_train)))\n",
    "    #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "    # Evaluating the Model Performance\n",
    "    rscore = r2_score(sc_y.inverse_transform(y_train), y_pred)\n",
    "    rmse_score = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    \n",
    "    # Evaluate the models using crossvalidation\n",
    "    if(len(X_train)>1):\n",
    "        scores = cross_val_score(regressor, X_train, y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=min(10,len(X_train)))\n",
    "    else:\n",
    "        scores = np.array([0])\n",
    "    \n",
    "    #print(best_sc)\n",
    "    #print(best_param)\n",
    "    \n",
    "    #print(\"MSE = {:.2e}(+/- {:.2e})\".format(-scores.mean(), scores.std()))\n",
    "    return regressor,rmse_score,-scores.mean(),scores.std(), rscore, best_sc, best_param, sc_X, sc_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "def RandomForestRegression_Regressor(train_df):\n",
    "    # Importing the dataset\n",
    "    dataset = train_df.copy()\n",
    "    #print(len(dataset))\n",
    "\n",
    "    X_train = dataset.iloc[:, :-1].values\n",
    "    y_train = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Training the Decision Tree Regression model on the Training set\n",
    "    regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regressor.predict(X_train)\n",
    "    #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train.reshape(len(y_train),1)),1))\n",
    "\n",
    "    # Evaluating the Model Performance\n",
    "    rscore = r2_score(y_train, y_pred)\n",
    "    #print(rscore)\n",
    "    rmse_score = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "     # Evaluate the models using crossvalidation\n",
    "    if(len(X_train)>1):\n",
    "        scores = cross_val_score(regressor, X_train, y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=min(10,len(X_train)))\n",
    "    else:\n",
    "        scores = np.array([0])\n",
    "        \n",
    "    #print(\"MSE = {:.2e}(+/- {:.2e})\".format(-scores.mean(), scores.std()))\n",
    "    return regressor,rmse_score,-scores.mean(),scores.std(), rscore, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost\n",
    "\n",
    "def XGB_Regressor(train_df):\n",
    "    # Importing the dataset\n",
    "    dataset = train_df.copy()\n",
    "    #print(len(dataset))\n",
    "\n",
    "    X_train = dataset.iloc[:, :-1].values\n",
    "    y_train = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Training the Decision Tree Regression model on the Training set\n",
    "    #regressor = XGBRegressor(max_depth = 15, n_estimators=1000)\n",
    "    regressor = XGBRegressor()\n",
    "    #eval_set = [(X_train, y_train)]\n",
    "    #eval_metric = [\"rmse\"]\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regressor.predict(X_train)\n",
    "    #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train.reshape(len(y_train),1)),1))\n",
    "\n",
    "    # Evaluating the Model Performance\n",
    "    rscore = r2_score(y_train, y_pred)\n",
    "    #print(rscore)\n",
    "    rmse_score = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    # Evaluate the models using crossvalidation\n",
    "    if(len(X_train)>1):\n",
    "        scores = cross_val_score(regressor, X_train, y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=min(10,len(X_train)))\n",
    "    else:\n",
    "        scores = np.array([0])\n",
    "        \n",
    "    #print(\"MSE = {:.2e}(+/- {:.2e})\".format(-scores.mean(), scores.std()))\n",
    "    return regressor,rmse_score,-scores.mean(),scores.std(), rscore, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Function\n",
    "\n",
    "def predict_function(regres_model, X_test):\n",
    "    # Predicting the Test set results\n",
    "    y_pred = regres_model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for the rows for which there is no description available\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "test_data_unique_desc = test_data_unique_desc[['CustomerID', 'Quantity', 'Country35', 'days_since_first_sold']]\n",
    "test_data_unique_desc = test_data_unique_desc.drop_duplicates()\n",
    "test_data_unique_desc.to_csv('test_data_unique_desc.csv', index = False)\n",
    "\n",
    "for cust_id, split_df in test_data_unique_desc.groupby('CustomerID'):\n",
    "    #print(cust_id)\n",
    "    \n",
    "    # Getting All data for that customerid from train data\n",
    "    #print('length before selecting customerid',len(train_df_NoDesc))\n",
    "    \n",
    "    # Just Trying\n",
    "    train_df_CountQuantDays_x = train_df_NoDesc[train_df_NoDesc['CustomerID'] == cust_id]\n",
    "    \n",
    "    #train_df_CountQuantDays_x = train_df_NoDesc.copy()\n",
    "    train_df_CountQuantDays_x.drop('CustomerID', axis = 1, inplace = True)\n",
    "    \n",
    "    #print('length after selecting customerid',len(train_df_CountQuantDays_x))\n",
    "    \n",
    "    # Removing CustomerID and aggregating\n",
    "    train_df_CountQuantDays_x = train_df_CountQuantDays_x.groupby(['days_since_first_sold', 'Country35','Quantity'], as_index = False).\\\n",
    "                                agg({'UnitPrice':'mean'})\n",
    "    \n",
    "    split_df = split_df[['days_since_first_sold', 'Country35','Quantity']]\n",
    "    split_df.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    # Drop duplicate and then Group by to get avg price in training data\n",
    "    # Fitting the model using a generic Function\n",
    "    #print('Training on columns',train_df_CountQuantDays_x.columns)\n",
    "    regressor, rscore_mlr, cv_mean, cv_sd, rscore = MultipleLinearRegression_Regressor(train_df_CountQuantDays_x)\n",
    "    X_test = split_df.iloc[:, :].values\n",
    "    y_pred = predict_function(regressor,X_test)\n",
    "    #print('Testing on columns',split_df.columns)\n",
    "    \n",
    "    split_df['y_pred'] = y_pred\n",
    "    \n",
    "    #overwriting by avg price\n",
    "    #split_df['y_pred'] = float(train_df_CountQuantDays_x['AvgPrice'].mean())\n",
    "    #print('Mean Value for the country', train_df_CountQuantDays_x['AvgPrice'].mean())\n",
    "    \n",
    "    split_df['CustomerID'] = cust_id\n",
    "    final_df = final_df.append(split_df)\n",
    "    #print(\"-------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "final_df.to_csv('final_df_test_custid.csv', index = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Country35</th>\n",
       "      <th>days_since_first_sold</th>\n",
       "      <th>Price_Mode_Sum</th>\n",
       "      <th>Price_MeanDesc</th>\n",
       "      <th>Price_MedianDesc</th>\n",
       "      <th>Price_MaxDesc</th>\n",
       "      <th>Price_MinDesc</th>\n",
       "      <th>Price_StDevDesc</th>\n",
       "      <th>Price_Mean_Customer</th>\n",
       "      <th>Price_StDev_Customer</th>\n",
       "      <th>Quantity_Mean</th>\n",
       "      <th>Quantity_Median</th>\n",
       "      <th>Quantity_Max</th>\n",
       "      <th>Quantity_Min</th>\n",
       "      <th>Quantity_StDev</th>\n",
       "      <th>Price_Mode1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16161</td>\n",
       "      <td>1079</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.364909</td>\n",
       "      <td>3.475940</td>\n",
       "      <td>7.684211</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>9.389774</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17341</td>\n",
       "      <td>3457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.193421</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.272806</td>\n",
       "      <td>2.082536</td>\n",
       "      <td>1.563595</td>\n",
       "      <td>5.527273</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>5.776243</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15158</td>\n",
       "      <td>694</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "      <td>7.70</td>\n",
       "      <td>3.871658</td>\n",
       "      <td>4.25</td>\n",
       "      <td>7.46</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.489634</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.376554</td>\n",
       "      <td>5.258389</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>7.243505</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16033</td>\n",
       "      <td>3473</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>206</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.642658</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.261951</td>\n",
       "      <td>3.418571</td>\n",
       "      <td>2.832470</td>\n",
       "      <td>11.314779</td>\n",
       "      <td>12.0</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>15.310779</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15351</td>\n",
       "      <td>871</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>23.70</td>\n",
       "      <td>12.654669</td>\n",
       "      <td>12.75</td>\n",
       "      <td>24.96</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.863610</td>\n",
       "      <td>2.833780</td>\n",
       "      <td>2.262824</td>\n",
       "      <td>3.704104</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>10.071870</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Description  Quantity  Country35  days_since_first_sold  \\\n",
       "0       16161         1079         3          1                     72   \n",
       "1       17341         3457         1          1                      6   \n",
       "2       15158          694        36          1                    328   \n",
       "3       16033         3473         2          1                    206   \n",
       "4       15351          871         1          1                    339   \n",
       "\n",
       "   Price_Mode_Sum  Price_MeanDesc  Price_MedianDesc  Price_MaxDesc  \\\n",
       "0            3.30        1.650000              1.65           1.65   \n",
       "1            2.08        1.193421              1.25           2.46   \n",
       "2            7.70        3.871658              4.25           7.46   \n",
       "3            3.10        1.642658              1.65           3.29   \n",
       "4           23.70       12.654669             12.75          24.96   \n",
       "\n",
       "   Price_MinDesc  Price_StDevDesc  Price_Mean_Customer  Price_StDev_Customer  \\\n",
       "0           1.65         0.000000             3.364909              3.475940   \n",
       "1           0.83         0.272806             2.082536              1.563595   \n",
       "2           2.95         0.489634             1.820000              1.376554   \n",
       "3           1.25         0.261951             3.418571              2.832470   \n",
       "4           8.12         0.863610             2.833780              2.262824   \n",
       "\n",
       "   Quantity_Mean  Quantity_Median  Quantity_Max  Quantity_Min  Quantity_StDev  \\\n",
       "0       7.684211              6.0            48             1        9.389774   \n",
       "1       5.527273              3.0            24             1        5.776243   \n",
       "2       5.258389              4.0            36             1        7.243505   \n",
       "3      11.314779             12.0           192             1       15.310779   \n",
       "4       3.704104              2.0           160             1       10.071870   \n",
       "\n",
       "   Price_Mode1  \n",
       "0         1.65  \n",
       "1         1.25  \n",
       "2         4.25  \n",
       "3         1.65  \n",
       "4        12.75  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_rep_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835\n",
      "119283\n",
      "14088 30\n",
      "14088 55\n",
      "14088 184\n",
      "14088 193\n",
      "14088 205\n",
      "14088 253\n",
      "14088 271\n",
      "14088 288\n",
      "14088 528\n",
      "14088 529\n",
      "14088 536\n",
      "14088 655\n",
      "14088 693\n",
      "14088 725\n",
      "14088 738\n",
      "14088 739\n",
      "14088 901\n",
      "14088 1015\n",
      "14088 1020\n",
      "14088 1022\n",
      "14088 1023\n",
      "14088 1033\n",
      "14088 1041\n",
      "14088 1132\n",
      "14088 1184\n",
      "14088 1203\n",
      "14088 1205\n",
      "14088 1286\n",
      "14088 1287\n",
      "14088 1320\n",
      "14088 1380\n",
      "14088 1381\n",
      "14088 1387\n",
      "14088 1443\n",
      "14088 1453\n",
      "14088 1487\n",
      "14088 1518\n",
      "14088 1535\n",
      "14088 1542\n",
      "14088 1658\n",
      "14088 1665\n",
      "14088 1770\n",
      "14088 1839\n",
      "14088 1870\n",
      "14088 2158\n",
      "14088 2328\n",
      "14088 2352\n",
      "14088 2403\n",
      "14088 2478\n",
      "14088 2539\n",
      "14088 2708\n",
      "14088 2741\n",
      "14088 2776\n",
      "14088 2780\n",
      "14088 2790\n",
      "14088 2934\n",
      "14088 2941\n",
      "14088 3006\n",
      "14088 3012\n",
      "14088 3124\n",
      "14088 3369\n",
      "14088 3398\n",
      "14088 3411\n",
      "14088 3424\n",
      "14088 3504\n",
      "14088 3553\n",
      "14088 3578\n",
      "14088 3580\n",
      "14088 3581\n",
      "14088 3696\n",
      "14088 3764\n",
      "14088 3772\n",
      "14088 3782\n",
      "14088 3883\n",
      "14096 12\n",
      "14096 19\n",
      "14096 45\n",
      "14096 48\n",
      "14096 52\n",
      "14096 54\n",
      "14096 58\n",
      "14096 59\n",
      "14096 63\n",
      "14096 69\n",
      "14096 74\n",
      "14096 75\n",
      "14096 86\n",
      "14096 101\n",
      "14096 102\n",
      "14096 103\n",
      "14096 104\n",
      "14096 105\n",
      "14096 106\n",
      "14096 109\n",
      "14096 113\n",
      "14096 120\n",
      "14096 132\n",
      "14096 133\n",
      "14096 139\n",
      "14096 141\n",
      "14096 142\n",
      "14096 143\n",
      "14096 146\n",
      "14096 147\n",
      "14096 149\n",
      "14096 165\n",
      "14096 178\n",
      "14096 182\n",
      "14096 194\n",
      "14096 195\n",
      "14096 199\n",
      "14096 203\n",
      "14096 223\n",
      "14096 249\n",
      "14096 256\n",
      "14096 257\n",
      "14096 258\n",
      "14096 261\n",
      "14096 271\n",
      "14096 272\n",
      "14096 276\n",
      "14096 285\n",
      "14096 300\n",
      "14096 301\n",
      "14096 303\n",
      "14096 304\n",
      "14096 318\n",
      "14096 327\n",
      "14096 330\n",
      "14096 331\n",
      "14096 332\n",
      "14096 376\n",
      "14096 380\n",
      "14096 390\n",
      "14096 407\n",
      "14096 431\n",
      "14096 440\n",
      "14096 441\n",
      "14096 458\n",
      "14096 472\n",
      "14096 473\n",
      "14096 477\n",
      "14096 494\n",
      "14096 512\n",
      "14096 524\n",
      "14096 525\n",
      "14096 526\n",
      "14096 532\n",
      "14096 543\n",
      "14096 549\n",
      "14096 550\n",
      "14096 556\n",
      "14096 564\n",
      "14096 568\n",
      "14096 588\n",
      "14096 589\n",
      "14096 597\n",
      "14096 610\n",
      "14096 615\n",
      "14096 617\n",
      "14096 618\n",
      "14096 619\n",
      "14096 624\n",
      "14096 626\n",
      "14096 628\n",
      "14096 629\n",
      "14096 630\n",
      "14096 652\n",
      "14096 656\n",
      "14096 666\n",
      "14096 670\n",
      "14096 672\n",
      "14096 673\n",
      "14096 678\n",
      "14096 679\n",
      "14096 684\n",
      "14096 689\n",
      "14096 690\n",
      "14096 694\n",
      "14096 695\n",
      "14096 699\n",
      "14096 703\n",
      "14096 704\n",
      "14096 707\n",
      "14096 725\n",
      "14096 730\n",
      "14096 731\n",
      "14096 733\n",
      "14096 738\n",
      "14096 739\n",
      "14096 741\n",
      "14096 744\n",
      "14096 745\n",
      "14096 747\n",
      "14096 748\n",
      "14096 749\n",
      "14096 754\n",
      "14096 757\n",
      "14096 759\n",
      "14096 761\n",
      "14096 762\n",
      "14096 763\n",
      "14096 766\n",
      "14096 768\n",
      "14096 769\n",
      "14096 777\n",
      "14096 799\n",
      "14096 809\n",
      "14096 815\n",
      "14096 823\n",
      "14096 825\n",
      "14096 826\n",
      "14096 829\n",
      "14096 844\n",
      "14096 849\n",
      "14096 852\n",
      "14096 857\n",
      "14096 909\n",
      "14096 953\n",
      "14096 973\n",
      "14096 975\n",
      "14096 979\n",
      "14096 997\n",
      "14096 999\n",
      "14096 1016\n",
      "14096 1018\n",
      "14096 1019\n",
      "14096 1020\n",
      "14096 1023\n",
      "14096 1024\n",
      "14096 1026\n",
      "14096 1031\n",
      "14096 1032\n",
      "14096 1033\n",
      "14096 1037\n",
      "14096 1039\n",
      "14096 1040\n",
      "14096 1042\n",
      "14096 1088\n",
      "14096 1091\n",
      "14096 1101\n",
      "14096 1110\n",
      "14096 1115\n",
      "14096 1127\n",
      "14096 1132\n",
      "14096 1149\n",
      "14096 1159\n",
      "14096 1167\n",
      "14096 1170\n",
      "14096 1171\n",
      "14096 1184\n",
      "14096 1185\n",
      "14096 1186\n",
      "14096 1187\n",
      "14096 1188\n",
      "14096 1191\n",
      "14096 1199\n",
      "14096 1201\n",
      "14096 1202\n",
      "14096 1204\n",
      "14096 1206\n",
      "14096 1209\n",
      "14096 1210\n",
      "14096 1213\n",
      "14096 1215\n",
      "14096 1217\n",
      "14096 1218\n",
      "14096 1221\n",
      "14096 1224\n",
      "14096 1248\n",
      "14096 1267\n",
      "14096 1268\n",
      "14096 1272\n",
      "14096 1282\n",
      "14096 1298\n",
      "14096 1300\n",
      "14096 1306\n",
      "14096 1313\n",
      "14096 1315\n",
      "14096 1317\n",
      "14096 1325\n",
      "14096 1326\n",
      "14096 1329\n",
      "14096 1331\n",
      "14096 1357\n",
      "14096 1358\n",
      "14096 1370\n",
      "14096 1376\n",
      "14096 1377\n",
      "14096 1386\n",
      "14096 1394\n",
      "14096 1399\n",
      "14096 1401\n",
      "14096 1402\n",
      "14096 1406\n",
      "14096 1410\n",
      "14096 1416\n",
      "14096 1435\n",
      "14096 1437\n",
      "14096 1438\n",
      "14096 1452\n",
      "14096 1468\n",
      "14096 1487\n",
      "14096 1518\n",
      "14096 1532\n",
      "14096 1535\n",
      "14096 1542\n",
      "14096 1551\n",
      "14096 1556\n",
      "14096 1557\n",
      "14096 1576\n",
      "14096 1577\n",
      "14096 1579\n",
      "14096 1585\n",
      "14096 1589\n",
      "14096 1603\n",
      "14096 1606\n",
      "14096 1609\n",
      "14096 1611\n",
      "14096 1614\n",
      "14096 1617\n",
      "14096 1618\n",
      "14096 1620\n",
      "14096 1628\n",
      "14096 1630\n",
      "14096 1654\n",
      "14096 1667\n",
      "14096 1676\n",
      "14096 1679\n",
      "14096 1688\n",
      "14096 1695\n",
      "14096 1708\n",
      "14096 1709\n",
      "14096 1710\n",
      "14096 1736\n",
      "14096 1737\n",
      "14096 1738\n",
      "14096 1753\n",
      "14096 1754\n",
      "14096 1756\n",
      "14096 1760\n",
      "14096 1762\n",
      "14096 1766\n",
      "14096 1770\n",
      "14096 1771\n",
      "14096 1772\n",
      "14096 1774\n",
      "14096 1777\n",
      "14096 1780\n",
      "14096 1781\n",
      "14096 1782\n",
      "14096 1784\n",
      "14096 1786\n",
      "14096 1792\n",
      "14096 1795\n",
      "14096 1802\n",
      "14096 1804\n",
      "14096 1807\n",
      "14096 1813\n",
      "14096 1815\n",
      "14096 1829\n",
      "14096 1848\n",
      "14096 1858\n",
      "14096 1868\n",
      "14096 1872\n",
      "14096 1873\n",
      "14096 1874\n",
      "14096 1876\n",
      "14096 1887\n",
      "14096 1924\n",
      "14096 1925\n",
      "14096 1926\n",
      "14096 1929\n",
      "14096 1934\n",
      "14096 1938\n",
      "14096 1943\n",
      "14096 1946\n",
      "14096 1950\n",
      "14096 1952\n",
      "14096 1953\n",
      "14096 1958\n",
      "14096 1962\n",
      "14096 1963\n",
      "14096 1965\n",
      "14096 1981\n",
      "14096 1986\n",
      "14096 1988\n",
      "14096 1990\n",
      "14096 1993\n",
      "14096 1999\n",
      "14096 2011\n",
      "14096 2013\n",
      "14096 2021\n",
      "14096 2033\n",
      "14096 2038\n",
      "14096 2047\n",
      "14096 2048\n",
      "14096 2053\n",
      "14096 2054\n",
      "14096 2055\n",
      "14096 2057\n",
      "14096 2081\n",
      "14096 2082\n",
      "14096 2090\n",
      "14096 2094\n",
      "14096 2095\n",
      "14096 2099\n",
      "14096 2108\n",
      "14096 2113\n",
      "14096 2118\n",
      "14096 2120\n",
      "14096 2145\n",
      "14096 2163\n",
      "14096 2168\n",
      "14096 2197\n",
      "14096 2198\n",
      "14096 2223\n",
      "14096 2230\n",
      "14096 2231\n",
      "14096 2232\n",
      "14096 2238\n",
      "14096 2241\n",
      "14096 2244\n",
      "14096 2245\n",
      "14096 2247\n",
      "14096 2248\n",
      "14096 2250\n",
      "14096 2252\n",
      "14096 2254\n",
      "14096 2255\n",
      "14096 2259\n",
      "14096 2264\n",
      "14096 2267\n",
      "14096 2269\n",
      "14096 2275\n",
      "14096 2276\n",
      "14096 2277\n",
      "14096 2278\n",
      "14096 2281\n",
      "14096 2286\n",
      "14096 2312\n",
      "14096 2313\n",
      "14096 2315\n",
      "14096 2316\n",
      "14096 2323\n",
      "14096 2326\n",
      "14096 2328\n",
      "14096 2344\n",
      "14096 2359\n",
      "14096 2369\n",
      "14096 2375\n",
      "14096 2385\n",
      "14096 2389\n",
      "14096 2390\n",
      "14096 2391\n",
      "14096 2394\n",
      "14096 2397\n",
      "14096 2400\n",
      "14096 2402\n",
      "14096 2409\n",
      "14096 2410\n",
      "14096 2416\n",
      "14096 2418\n",
      "14096 2419\n",
      "14096 2427\n",
      "14096 2433\n",
      "14096 2437\n",
      "14096 2446\n",
      "14096 2454\n",
      "14096 2461\n",
      "14096 2462\n",
      "14096 2464\n",
      "14096 2469\n",
      "14096 2492\n",
      "14096 2498\n",
      "14096 2531\n",
      "14096 2539\n",
      "14096 2560\n",
      "14096 2577\n",
      "14096 2578\n",
      "14096 2583\n",
      "14096 2585\n",
      "14096 2594\n",
      "14096 2601\n",
      "14096 2612\n",
      "14096 2616\n",
      "14096 2622\n",
      "14096 2628\n",
      "14096 2631\n",
      "14096 2633\n",
      "14096 2637\n",
      "14096 2663\n",
      "14096 2669\n",
      "14096 2671\n",
      "14096 2672\n",
      "14096 2676\n",
      "14096 2678\n",
      "14096 2681\n",
      "14096 2690\n",
      "14096 2693\n",
      "14096 2708\n",
      "14096 2709\n",
      "14096 2713\n",
      "14096 2721\n",
      "14096 2728\n",
      "14096 2737\n",
      "14096 2738\n",
      "14096 2739\n",
      "14096 2743\n",
      "14096 2745\n",
      "14096 2746\n",
      "14096 2751\n",
      "14096 2752\n",
      "14096 2756\n",
      "14096 2758\n",
      "14096 2760\n",
      "14096 2768\n",
      "14096 2769\n",
      "14096 2776\n",
      "14096 2780\n",
      "14096 2787\n",
      "14096 2789\n",
      "14096 2791\n",
      "14096 2792\n",
      "14096 2802\n",
      "14096 2813\n",
      "14096 2815\n",
      "14096 2818\n",
      "14096 2821\n",
      "14096 2822\n",
      "14096 2825\n",
      "14096 2826\n",
      "14096 2827\n",
      "14096 2830\n",
      "14096 2832\n",
      "14096 2834\n",
      "14096 2836\n",
      "14096 2837\n",
      "14096 2838\n",
      "14096 2862\n",
      "14096 2864\n",
      "14096 2874\n",
      "14096 2878\n",
      "14096 2879\n",
      "14096 2880\n",
      "14096 2885\n",
      "14096 2891\n",
      "14096 2912\n",
      "14096 2913\n",
      "14096 2916\n",
      "14096 2925\n",
      "14096 2928\n",
      "14096 2929\n",
      "14096 2930\n",
      "14096 2935\n",
      "14096 2938\n",
      "14096 2949\n",
      "14096 2955\n",
      "14096 2971\n",
      "14096 2975\n",
      "14096 2977\n",
      "14096 2982\n",
      "14096 2996\n",
      "14096 2999\n",
      "14096 3002\n",
      "14096 3003\n",
      "14096 3008\n",
      "14096 3013\n",
      "14096 3014\n",
      "14096 3015\n",
      "14096 3019\n",
      "14096 3020\n",
      "14096 3022\n",
      "14096 3025\n",
      "14096 3026\n",
      "14096 3027\n",
      "14096 3028\n",
      "14096 3029\n",
      "14096 3035\n",
      "14096 3038\n",
      "14096 3040\n",
      "14096 3043\n",
      "14096 3059\n",
      "14096 3063\n",
      "14096 3065\n",
      "14096 3069\n",
      "14096 3070\n",
      "14096 3072\n",
      "14096 3073\n",
      "14096 3075\n",
      "14096 3076\n",
      "14096 3082\n",
      "14096 3088\n",
      "14096 3091\n",
      "14096 3093\n",
      "14096 3094\n",
      "14096 3099\n",
      "14096 3100\n",
      "14096 3101\n",
      "14096 3113\n",
      "14096 3118\n",
      "14096 3119\n",
      "14096 3120\n",
      "14096 3121\n",
      "14096 3132\n",
      "14096 3133\n",
      "14096 3143\n",
      "14096 3147\n",
      "14096 3151\n",
      "14096 3152\n",
      "14096 3155\n",
      "14096 3160\n",
      "14096 3165\n",
      "14096 3170\n",
      "14096 3192\n",
      "14096 3199\n",
      "14096 3231\n",
      "14096 3254\n",
      "14096 3256\n",
      "14096 3259\n",
      "14096 3262\n",
      "14096 3266\n",
      "14096 3273\n",
      "14096 3281\n",
      "14096 3284\n",
      "14096 3285\n",
      "14096 3286\n",
      "14096 3287\n",
      "14096 3301\n",
      "14096 3312\n",
      "14096 3316\n",
      "14096 3323\n",
      "14096 3325\n",
      "14096 3327\n",
      "14096 3328\n",
      "14096 3339\n",
      "14096 3351\n",
      "14096 3354\n",
      "14096 3355\n",
      "14096 3364\n",
      "14096 3368\n",
      "14096 3369\n",
      "14096 3371\n",
      "14096 3375\n",
      "14096 3377\n",
      "14096 3385\n",
      "14096 3392\n",
      "14096 3400\n",
      "14096 3409\n",
      "14096 3411\n",
      "14096 3414\n",
      "14096 3419\n",
      "14096 3420\n",
      "14096 3425\n",
      "14096 3426\n",
      "14096 3427\n",
      "14096 3428\n",
      "14096 3430\n",
      "14096 3435\n",
      "14096 3440\n",
      "14096 3457\n",
      "14096 3460\n",
      "14096 3461\n",
      "14096 3463\n",
      "14096 3464\n",
      "14096 3469\n",
      "14096 3470\n",
      "14096 3472\n",
      "14096 3473\n",
      "14096 3474\n",
      "14096 3477\n",
      "14096 3484\n",
      "14096 3485\n",
      "14096 3501\n",
      "14096 3509\n",
      "14096 3510\n",
      "14096 3531\n",
      "14096 3537\n",
      "14096 3541\n",
      "14096 3542\n",
      "14096 3550\n",
      "14096 3556\n",
      "14096 3557\n",
      "14096 3558\n",
      "14096 3563\n",
      "14096 3569\n",
      "14096 3574\n",
      "14096 3584\n",
      "14096 3585\n",
      "14096 3598\n",
      "14096 3629\n",
      "14096 3630\n",
      "14096 3681\n",
      "14096 3682\n",
      "14096 3716\n",
      "14096 3725\n",
      "14096 3762\n",
      "14096 3766\n",
      "14096 3770\n",
      "14096 3771\n",
      "14096 3772\n",
      "14096 3774\n",
      "14096 3775\n",
      "14096 3776\n",
      "14096 3777\n",
      "14096 3778\n",
      "14096 3780\n",
      "14096 3783\n",
      "14096 3785\n",
      "14096 3786\n",
      "14096 3791\n",
      "14096 3798\n",
      "14096 3860\n",
      "14096 3875\n",
      "14096 3876\n",
      "14096 3883\n",
      "14096 3891\n",
      "14096 3893\n",
      "14298 113\n",
      "14298 203\n",
      "14298 205\n",
      "14298 211\n",
      "14298 223\n",
      "14298 225\n",
      "14298 231\n",
      "14298 240\n",
      "14298 244\n",
      "14298 247\n",
      "14298 251\n",
      "14298 261\n",
      "14298 286\n",
      "14298 299\n",
      "14298 312\n",
      "14298 324\n",
      "14298 337\n",
      "14298 339\n",
      "14298 340\n",
      "14298 342\n",
      "14298 345\n",
      "14298 376\n",
      "14298 388\n",
      "14298 418\n",
      "14298 466\n",
      "14298 494\n",
      "14298 523\n",
      "14298 543\n",
      "14298 585\n",
      "14298 597\n",
      "14298 598\n",
      "14298 664\n",
      "14298 676\n",
      "14298 677\n",
      "14298 678\n",
      "14298 679\n",
      "14298 689\n",
      "14298 690\n",
      "14298 694\n",
      "14298 725\n",
      "14298 726\n",
      "14298 732\n",
      "14298 756\n",
      "14298 782\n",
      "14298 810\n",
      "14298 817\n",
      "14298 825\n",
      "14298 857\n",
      "14298 892\n",
      "14298 893\n",
      "14298 909\n",
      "14298 928\n",
      "14298 932\n",
      "14298 978\n",
      "14298 1088\n",
      "14298 1114\n",
      "14298 1115\n",
      "14298 1146\n",
      "14298 1151\n",
      "14298 1159\n",
      "14298 1186\n",
      "14298 1219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14298 1221\n",
      "14298 1224\n",
      "14298 1235\n",
      "14298 1236\n",
      "14298 1275\n",
      "14298 1342\n",
      "14298 1361\n",
      "14298 1396\n",
      "14298 1402\n",
      "14298 1427\n",
      "14298 1430\n",
      "14298 1444\n",
      "14298 1480\n",
      "14298 1481\n",
      "14298 1518\n",
      "14298 1535\n",
      "14298 1542\n",
      "14298 1544\n",
      "14298 1551\n",
      "14298 1553\n",
      "14298 1554\n",
      "14298 1577\n",
      "14298 1578\n",
      "14298 1579\n",
      "14298 1581\n",
      "14298 1585\n",
      "14298 1602\n",
      "14298 1607\n",
      "14298 1609\n",
      "14298 1610\n",
      "14298 1613\n",
      "14298 1614\n",
      "14298 1617\n",
      "14298 1618\n",
      "14298 1649\n",
      "14298 1666\n",
      "14298 1669\n",
      "14298 1679\n",
      "14298 1691\n",
      "14298 1692\n",
      "14298 1701\n",
      "14298 1736\n",
      "14298 1741\n",
      "14298 1754\n",
      "14298 1759\n",
      "14298 1760\n",
      "14298 1761\n",
      "14298 1763\n",
      "14298 1765\n",
      "14298 1766\n",
      "14298 1769\n",
      "14298 1770\n",
      "14298 1772\n",
      "14298 1774\n",
      "14298 1775\n",
      "14298 1776\n",
      "14298 1781\n",
      "14298 1783\n",
      "14298 1784\n",
      "14298 1813\n",
      "14298 1821\n",
      "14298 1838\n",
      "14298 1839\n",
      "14298 1855\n",
      "14298 1874\n",
      "14298 1875\n",
      "14298 1879\n",
      "14298 1936\n",
      "14298 1938\n",
      "14298 1939\n",
      "14298 1943\n",
      "14298 1973\n",
      "14298 2024\n",
      "14298 2041\n",
      "14298 2058\n",
      "14298 2110\n",
      "14298 2111\n",
      "14298 2113\n",
      "14298 2117\n",
      "14298 2119\n",
      "14298 2129\n",
      "14298 2133\n",
      "14298 2139\n",
      "14298 2142\n",
      "14298 2143\n",
      "14298 2145\n",
      "14298 2146\n",
      "14298 2165\n",
      "14298 2166\n",
      "14298 2203\n",
      "14298 2265\n",
      "14298 2289\n",
      "14298 2356\n",
      "14298 2369\n",
      "14298 2393\n",
      "14298 2394\n",
      "14298 2400\n",
      "14298 2420\n",
      "14298 2435\n",
      "14298 2462\n",
      "14298 2464\n",
      "14298 2539\n",
      "14298 2552\n",
      "14298 2612\n",
      "14298 2619\n",
      "14298 2643\n",
      "14298 2663\n",
      "14298 2681\n",
      "14298 2702\n",
      "14298 2713\n",
      "14298 2737\n",
      "14298 2766\n",
      "14298 2770\n",
      "14298 2778\n",
      "14298 2780\n",
      "14298 2783\n",
      "14298 2784\n",
      "14298 2787\n",
      "14298 2788\n",
      "14298 2790\n",
      "14298 2793\n",
      "14298 2801\n",
      "14298 2826\n",
      "14298 2918\n",
      "14298 2935\n",
      "14298 2960\n",
      "14298 2972\n",
      "14298 2975\n",
      "14298 2983\n",
      "14298 3011\n",
      "14298 3026\n",
      "14298 3041\n",
      "14298 3071\n",
      "14298 3087\n",
      "14298 3089\n",
      "14298 3097\n",
      "14298 3100\n",
      "14298 3151\n",
      "14298 3152\n",
      "14298 3181\n",
      "14298 3195\n",
      "14298 3213\n",
      "14298 3256\n",
      "14298 3259\n",
      "14298 3267\n",
      "14298 3283\n",
      "14298 3298\n",
      "14298 3317\n",
      "14298 3371\n",
      "14298 3378\n",
      "14298 3412\n",
      "14298 3420\n",
      "14298 3446\n",
      "14298 3459\n",
      "14298 3460\n",
      "14298 3467\n",
      "14298 3484\n",
      "14298 3489\n",
      "14298 3512\n",
      "14298 3513\n",
      "14298 3532\n",
      "14298 3595\n",
      "14298 3642\n",
      "14298 3681\n",
      "14298 3695\n",
      "14298 3696\n",
      "14298 3714\n",
      "14298 3716\n",
      "14298 3722\n",
      "14298 3723\n",
      "14298 3724\n",
      "14298 3733\n",
      "14298 3737\n",
      "14298 3740\n",
      "14298 3778\n",
      "14298 3791\n",
      "14298 3889\n",
      "17450 144\n",
      "17450 283\n",
      "17450 285\n",
      "17450 326\n",
      "17450 837\n",
      "17450 918\n",
      "17450 981\n",
      "17450 1017\n",
      "17450 1019\n",
      "17450 1024\n",
      "17450 1027\n",
      "17450 1030\n",
      "17450 1031\n",
      "17450 1396\n",
      "17450 1524\n",
      "17450 1617\n",
      "17450 1618\n",
      "17450 1671\n",
      "17450 1679\n",
      "17450 1696\n",
      "17450 1738\n",
      "17450 1807\n",
      "17450 1872\n",
      "17450 2020\n",
      "17450 2023\n",
      "17450 2166\n",
      "17450 2316\n",
      "17450 2398\n",
      "17450 2592\n",
      "17450 2627\n",
      "17450 2628\n",
      "17450 3089\n",
      "17450 3111\n",
      "17450 3338\n",
      "17450 3460\n",
      "17450 3553\n",
      "17450 3681\n",
      "17450 3683\n",
      "17450 3716\n"
     ]
    }
   ],
   "source": [
    "# Predicting for the rows for which there is customer in special list\n",
    "\n",
    "final_df_cust = pd.DataFrame()\n",
    "\n",
    "test_data_rep_desc1 = test_data_rep_desc[['CustomerID', 'Description', 'Quantity', 'Country35',\\\n",
    "                                          'Price_Mode_Sum','days_since_first_sold'] + var_list]\n",
    "test_data_rep_desc1 = test_data_rep_desc1.drop_duplicates()\n",
    "#test_data_rep_desc.to_csv('test_data_rep_desc.csv', index = False)\n",
    "test_data_rep_desc1['key'] = range(len(test_data_rep_desc1))\n",
    "\n",
    "#cust_uniq = train_df_customers['CustomerID'].unique()\n",
    "\n",
    "train_df_customers_unique = train_df_customers[['CustomerID', 'Description']].drop_duplicates()\n",
    "\n",
    "test_data_rep_desc_cust = train_df_customers_unique.merge(test_data_rep_desc1, on =['CustomerID', 'Description'],\\\n",
    "                                                          how = 'inner')\n",
    "\n",
    "test_data_rep_desc_norm = test_data_rep_desc1[~test_data_rep_desc1['key'].isin(test_data_rep_desc_cust['key'])]\n",
    "\n",
    "test_data_rep_desc_cust.drop('key', axis = 1, inplace = True)\n",
    "test_data_rep_desc_norm.drop('key', axis = 1, inplace = True)\n",
    "\n",
    "test_data_rep_desc_cust.drop('Price_Mode_Sum', axis =1, inplace = True)\n",
    "test_data_rep_desc_cust.drop(var_list, axis =1, inplace = True)\n",
    "#test_data_rep_desc_cust = test_data_rep_desc[test_data_rep_desc['CustomerID'].isin(cust_uniq)]\n",
    "#test_data_rep_desc_norm = test_data_rep_desc[~test_data_rep_desc['CustomerID'].isin(cust_uniq)]\n",
    "print(len(test_data_rep_desc_cust))\n",
    "print(len(test_data_rep_desc_norm))\n",
    "\n",
    "for key, split_df in test_data_rep_desc_cust.groupby(['CustomerID', 'Description']):\n",
    "    cust_id = key[0]\n",
    "    desc_id = key[1]\n",
    "    print(cust_id, desc_id)\n",
    "    \n",
    "    # Getting All data for that customerid from train data\n",
    "    #print('length before selecting customerid',len(train_df_customers))\n",
    "    \n",
    "    # Filtering\n",
    "    train_df_x = train_df_customers[(train_df_customers['CustomerID'] == cust_id) & \\\n",
    "                                    (train_df_customers['Description'] == desc_id)]\n",
    "    \n",
    "    \n",
    "    train_df_x.drop('CustomerID', axis = 1, inplace = True)\n",
    "    train_df_x.drop('Description', axis = 1, inplace = True)\n",
    "    \n",
    "    #print('length after selecting customerid',len(train_df_CountQuantDays_x))\n",
    "    \n",
    "    # Removing CustomerID and aggregating\n",
    "    train_df_x = train_df_x.groupby(['days_since_first_sold', 'Country35','Quantity'], as_index = False).\\\n",
    "                                agg({'UnitPrice':'mean'})\n",
    "    \n",
    "    split_df = split_df[['days_since_first_sold', 'Country35','Quantity']]\n",
    "    split_df.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    # Drop duplicate and then Group by to get avg price in training data\n",
    "    # Fitting the model using a generic Function\n",
    "    #print('Training on columns',train_df_CountQuantDays_x.columns)\n",
    "    #regressor, rscore_mlr, cv_mean, cv_sd, rscore = MultipleLinearRegression_Regressor(train_df_CountQuantDays_x)\n",
    "    regressor, rscore_mlr, cv_mean, cv_sd, rscore, y_pred_dt_x = DecisionTreeRegression_Regressor(train_df_x)\n",
    "    \n",
    "    X_test = split_df.iloc[:, :].values\n",
    "    y_pred = predict_function(regressor,X_test)\n",
    "    #print('Testing on columns',split_df.columns)\n",
    "    \n",
    "    split_df['y_pred'] = y_pred\n",
    "    \n",
    "    #overwriting by avg price\n",
    "    #split_df['y_pred'] = float(train_df_CountQuantDays_x['AvgPrice'].mean())\n",
    "    #print('Mean Value for the country', train_df_CountQuantDays_x['AvgPrice'].mean())\n",
    "    \n",
    "    split_df['CustomerID'] = cust_id\n",
    "    split_df['Description'] = desc_id\n",
    "    final_df_cust = final_df_cust.append(split_df)\n",
    "    #print(\"-------------------------------------------------------------------------------------------\")\n",
    "    #break\n",
    "    \n",
    "final_df_cust.to_csv('final_df_test_custid.csv', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BAD Description\n",
    "\n",
    "#train_df_in = \n",
    "#test_df_in = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for the rows for which there is a description available in training data and Evaluating all Models\n",
    "\n",
    "final_df_desc = pd.DataFrame()\n",
    "\n",
    "#test_data_rep_desc_norm = test_data_rep_desc_norm[['Description', 'Quantity', 'Country35','days_since_first_sold','Price_Mode_Sum']]\n",
    "#test_data_rep_desc_norm = test_data_rep_desc_norm.drop_duplicates()\n",
    "test_data_rep_desc_norm1 = test_data_rep_desc_norm[[ 'Price_Mode_Sum','Quantity', 'Country35','days_since_first_sold']\\\n",
    "                                                  +var_list ]\n",
    "\n",
    "train_df_normal = pd.DataFrame()\n",
    "\n",
    "i =0\n",
    "\n",
    "score_df = pd.DataFrame()\n",
    "\n",
    "complete_list = [ 'Quantity','Country35', 'days_since_first_sold']+var_list\n",
    "target_col = 'UnitPrice'\n",
    "\n",
    "for description_id, split_df in test_data_rep_desc_norm1.groupby('Price_Mode_Sum'):\n",
    "    #print('-------------------------',description_id, '---------------------------------')\n",
    "    # Getting All data for that country from train data\n",
    "    train_df_x = train_df[train_df['Price_Mode_Sum'] == description_id]\n",
    "    count_descriptions = train_df_x['Description'].nunique()\n",
    "    \n",
    "    train_df_x = train_df_x.sort_values(['days_since_first_sold'], ascending = True)\n",
    "    train_df_x.index = range(len(train_df_x))\n",
    "    \n",
    "    train_df_x2 = train_df_x.copy()\n",
    "    \n",
    "    # Changing Column Orders\n",
    "    split_df = split_df[complete_list]\n",
    "    train_df_x = train_df_x[complete_list+[target_col]]\n",
    "    split_df.index = range(len(split_df))\n",
    "    \n",
    "    \n",
    "    val1 = train_df_x.loc[0,'UnitPrice']\n",
    "    val2 = train_df_x.loc[len(train_df_x)-1,'UnitPrice']\n",
    "   \n",
    "    X_test = split_df.iloc[:, :].values\n",
    "        \n",
    "    #print('Training on columns',train_df_x.columns)\n",
    "    #print('Testing on columns',split_df.columns)\n",
    "    \n",
    "    # Fitting the model using a generic Function\n",
    "    \n",
    "    #Multiple Linear Regression Model\n",
    "    #regressor_mlr, rmse_mlr, cv_mean_mlr, cv_sd_mlr, rscore_mlr = MultipleLinearRegression_Regressor( train_df_x )\n",
    "    \n",
    "    #Decision Tree Model\n",
    "    regressor_dt, rmse_dt, cv_mean_dt, cv_sd_dt, rscore_dt, y_pred_dt_x = DecisionTreeRegression_Regressor( train_df_x )\n",
    "    \n",
    "    #Decision Tree Model Classification\n",
    "    regressor_dt_clf, rmse_dt_clf, cv_mean_dt_clf, cv_sd_dt_clf, rscore_dt_clf, y_pred_dt_clf_x = DecisionTreeClassification_Regressor( train_df_x )\n",
    "    \n",
    "    #SVR Model\n",
    "    #Feature Scaling\n",
    "    #regressor_svr, rmse_svr, cv_mean_svr, cv_sd_svr, rscore_svr, best_sc, best_param, sc_X, sc_y = SVR_Regressor\\\n",
    "    #                                                                               ( train_df_x ) \n",
    "    \n",
    "    #Random Forest Model\n",
    "    regressor_rf, rmse_rf, cv_mean_rf, cv_sd_rf, rscore_rf, y_pred_rf = RandomForestRegression_Regressor( train_df_x )\n",
    "    \n",
    "    #XGB_Regressor\n",
    "    regressor_xgb, rmse_xgb, cv_mean_xgb, cv_sd_xgb, rscore_xgb, y_pred_xgb = XGB_Regressor( train_df_x )\n",
    "    \n",
    "    #print(X_test)\n",
    "    \n",
    "    #if cv_mean_svr+cv_sd_svr < cv_mean_dt+cv_sd_dt:\n",
    "    len_uniq = len(train_df_x['UnitPrice'].unique())\n",
    "    \n",
    "    # If error Condition\n",
    "    y_pred = predict_function(regressor_dt, X_test)\n",
    "    \n",
    "    \n",
    "    #split_df['y_mlr'] = predict_function(regressor_mlr, X_test)\n",
    "    split_df['y_dt'] = predict_function(regressor_dt, X_test)\n",
    "    split_df['y_dt_clf'] = predict_function(regressor_dt_clf, X_test)\n",
    "    #split_df['y_svr'] = sc_y.inverse_transform(regressor_svr.predict(sc_X.transform(X_test)))\n",
    "    split_df['y_rf'] = predict_function(regressor_rf, X_test)\n",
    "    split_df['y_xgb'] = predict_function(regressor_xgb, X_test)\n",
    "    \n",
    "    # Checking if there is only one value in the unique price\n",
    "    \n",
    "    if len_uniq == 1:\n",
    "        split_df['y_pred'] = list(train_df_x['UnitPrice'].unique())[0]\n",
    "        \n",
    "    else:\n",
    "        split_df['y_pred'] = y_pred\n",
    "    \n",
    "    # Adding Description combining to the overall dataset\n",
    "    split_df['Price_Mode_Sum'] = description_id\n",
    "    final_df_desc = final_df_desc.append(split_df)\n",
    "    if i%100 == 0:\n",
    "        print(description_id)\n",
    "    \n",
    "    score_df_temp = pd.DataFrame({'Description':  [description_id], \\\n",
    "                                  #'rmse_mlr':[rmse_mlr],\\\n",
    "                                  'rmse_dt': [rmse_dt],\\\n",
    "                                  'rmse_dt_clf': [rmse_dt_clf],\\\n",
    "                                  #'rmse_svr':[rmse_svr],\\\n",
    "                                  'rmse_rf':[rmse_rf],\\\n",
    "                                  'rmse_xgb':[rmse_xgb],\\\n",
    "                                  #'rscore_mlr':[rscore_mlr],\\\n",
    "                                  'rscore_dt':[rscore_dt],\\\n",
    "                                  'rscore_dt_clf':[rscore_dt_clf],\\\n",
    "                                  #'rscore_svr':[rscore_svr],\\\n",
    "                                  'rscore_rf':[rscore_rf],\\\n",
    "                                  'rscore_xgb':[rscore_xgb],\\\n",
    "                                  'depth_dt':[regressor_dt.tree_.max_depth],\\\n",
    "                                  'depth_dt_clf':[regressor_dt_clf.tree_.max_depth],\\\n",
    "                                  #'depth_rf':[regressor_rf.tree_.max_depth],\\\n",
    "                                  #'depth_xgb':[regressor_xgb.tree_.max_depth],\\\n",
    "                                  #'cv_mean_mlr':[cv_mean_mlr],\\\n",
    "                                  'cv_mean_dt':[cv_mean_dt],\\\n",
    "                                  'cv_mean_dt_clf':[cv_mean_dt_clf],\\\n",
    "                                  #'cv_mean_svr':[cv_mean_svr],\\\n",
    "                                  'cv_mean_rf':[cv_mean_rf],\\\n",
    "                                  'cv_mean_xgb':[cv_mean_xgb],\\\n",
    "                                  #'cv_sd_mlr':[cv_sd_mlr],\\\n",
    "                                  'cv_sd_dt':[cv_sd_dt],\\\n",
    "                                  'cv_sd_dt_clf':[cv_sd_dt_clf],\\\n",
    "                                  #'cv_sd_svr':[cv_sd_svr],\\\n",
    "                                  #'cv_sd_rf':[cv_sd_rf],\\\n",
    "                                  #'cv_sd_xgb':[cv_sd_xgb],\\\n",
    "                                  #'svr_best_sc':[best_sc], 'svr_best_param':[best_param],\\\n",
    "                                  'length_of_train': [len(train_df_x)],\\\n",
    "                                  'unique_length':[len_uniq],\\\n",
    "                                  'length_of_test':[len(split_df)],\\\n",
    "                                  'first_last_same':[(val1 == val2)],\\\n",
    "                                  'count_descriptions':count_descriptions,\\\n",
    "                                  'length_available_in_org_test':[len(test_df_org[test_df_org['Description'] == description_id])  ]})\n",
    "    \n",
    "    score_df = score_df.append(score_df_temp)\n",
    "    i += 1\n",
    "    \n",
    "    #train_df_x2['Description'] = description_id\n",
    "    train_df_x2['y_pred_dt'] = y_pred_dt_x\n",
    "    train_df_x2['y_pred_dt_clf'] = y_pred_dt_clf_x\n",
    "    train_df_x2['y_pred_rf'] = y_pred_rf\n",
    "    train_df_x2['y_pred_xgb'] = y_pred_xgb\n",
    "    train_df_normal = train_df_normal.append(train_df_x2)\n",
    "    #if i>10:\n",
    "    #    break\n",
    "    \n",
    "final_df_desc.to_csv('final_df_test_desc.csv', index = False)\n",
    "score_df.to_csv('score_df_desc.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Description Var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "109\n",
      "223\n",
      "335\n",
      "458\n",
      "568\n",
      "677\n",
      "781\n",
      "902\n",
      "1021\n",
      "1131\n",
      "1245\n",
      "1360\n",
      "1486\n",
      "1592\n",
      "1701\n",
      "1809\n",
      "1929\n",
      "2035\n",
      "2143\n",
      "2263\n",
      "2368\n",
      "2493\n",
      "2613\n",
      "2731\n",
      "2833\n",
      "2949\n",
      "3053\n",
      "3157\n",
      "3267\n",
      "3371\n",
      "3479\n",
      "3590\n",
      "3706\n",
      "3823\n"
     ]
    }
   ],
   "source": [
    "# Predicting for the rows for which there is a description available in training data and Evaluating all Models\n",
    "\n",
    "final_df_desc2 = pd.DataFrame()\n",
    "var_list2 = []\n",
    "\n",
    "#test_data_rep_desc_norm = test_data_rep_desc_norm[['Description', 'Quantity', 'Country35','days_since_first_sold','Price_Mode_Sum']]\n",
    "#test_data_rep_desc_norm = test_data_rep_desc_norm.drop_duplicates()\n",
    "test_data_rep_desc_norm2 = test_data_rep_desc_norm[[ 'Description','Quantity', 'Country35','days_since_first_sold']\\\n",
    "                                                  +var_list2 ]\n",
    "\n",
    "train_df_normal2 = pd.DataFrame()\n",
    "\n",
    "i =0\n",
    "\n",
    "score_df2 = pd.DataFrame()\n",
    "\n",
    "\n",
    "complete_list = [ 'Quantity','Country35', 'days_since_first_sold']+var_list2\n",
    "target_col = 'UnitPrice'\n",
    "\n",
    "for description_id, split_df in test_data_rep_desc_norm2.groupby('Description'):\n",
    "    #print('-------------------------',description_id, '---------------------------------')\n",
    "    # Getting All data for that country from train data\n",
    "    train_df_x = train_df[train_df['Description'] == description_id]\n",
    "    \n",
    "    train_df_x = train_df_x.sort_values(['days_since_first_sold'], ascending = True)\n",
    "    train_df_x.index = range(len(train_df_x))\n",
    "    \n",
    "    train_df_x2 = train_df_x.copy()\n",
    "    \n",
    "    # Changing Column Orders\n",
    "    split_df = split_df[complete_list]\n",
    "    train_df_x = train_df_x[complete_list+[target_col]]\n",
    "    split_df.index = range(len(split_df))\n",
    "    \n",
    "    \n",
    "    val1 = train_df_x.loc[0,'UnitPrice']\n",
    "    val2 = train_df_x.loc[len(train_df_x)-1,'UnitPrice']\n",
    "   \n",
    "    X_test = split_df.iloc[:, :].values\n",
    "        \n",
    "    #print('Training on columns',train_df_x.columns)\n",
    "    #print('Testing on columns',split_df.columns)\n",
    "    \n",
    "    # Fitting the model using a generic Function\n",
    "    \n",
    "    #Multiple Linear Regression Model\n",
    "    #regressor_mlr, rmse_mlr, cv_mean_mlr, cv_sd_mlr, rscore_mlr = MultipleLinearRegression_Regressor( train_df_x )\n",
    "    \n",
    "    #Decision Tree Model\n",
    "    regressor_dt, rmse_dt, cv_mean_dt, cv_sd_dt, rscore_dt, y_pred_dt_x = DecisionTreeRegression_Regressor( train_df_x )\n",
    "    \n",
    "    #Decision Tree Model Classification\n",
    "    regressor_dt_clf, rmse_dt_clf, cv_mean_dt_clf, cv_sd_dt_clf, rscore_dt_clf, y_pred_dt_clf_x = DecisionTreeClassification_Regressor( train_df_x )\n",
    "    \n",
    "    #SVR Model\n",
    "    #Feature Scaling\n",
    "    #regressor_svr, rmse_svr, cv_mean_svr, cv_sd_svr, rscore_svr, best_sc, best_param, sc_X, sc_y = SVR_Regressor\\\n",
    "    #                                                                               ( train_df_x ) \n",
    "    \n",
    "    #Random Forest Model\n",
    "    regressor_rf, rmse_rf, cv_mean_rf, cv_sd_rf, rscore_rf, y_pred_rf = RandomForestRegression_Regressor( train_df_x )\n",
    "    \n",
    "    #XGB_Regressor\n",
    "    regressor_xgb, rmse_xgb, cv_mean_xgb, cv_sd_xgb, rscore_xgb, y_pred_xgb = XGB_Regressor( train_df_x )\n",
    "    \n",
    "    #print(X_test)\n",
    "    \n",
    "    #if cv_mean_svr+cv_sd_svr < cv_mean_dt+cv_sd_dt:\n",
    "    len_uniq = len(train_df_x['UnitPrice'].unique())\n",
    "    \n",
    "    # If error Condition\n",
    "    if len_uniq==2:\n",
    "         y_pred = predict_function(regressor_dt_clf, X_test)\n",
    "    else:\n",
    "        y_pred = predict_function(regressor_dt, X_test)\n",
    "    \n",
    "    \n",
    "    #split_df['y_mlr'] = predict_function(regressor_mlr, X_test)\n",
    "    split_df['y_dt'] = predict_function(regressor_dt, X_test)\n",
    "    split_df['y_dt_clf'] = predict_function(regressor_dt_clf, X_test)\n",
    "    #split_df['y_svr'] = sc_y.inverse_transform(regressor_svr.predict(sc_X.transform(X_test)))\n",
    "    split_df['y_rf'] = predict_function(regressor_rf, X_test)\n",
    "    split_df['y_xgb'] = predict_function(regressor_xgb, X_test)\n",
    "    \n",
    "    # Checking if there is only one value in the unique price\n",
    "    \n",
    "    if len_uniq == 1:\n",
    "        split_df['y_pred'] = list(train_df_x['UnitPrice'].unique())[0]\n",
    "        \n",
    "    else:\n",
    "        split_df['y_pred'] = y_pred\n",
    "    \n",
    "    # Adding Description combining to the overall dataset\n",
    "    split_df['Description'] = description_id\n",
    "    final_df_desc2 = final_df_desc2.append(split_df)\n",
    "    if i%100 == 0:\n",
    "        print(description_id)\n",
    "        #print('R-score', rscore_dt)\n",
    "        #print(\"-------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    #print(description_id)\n",
    "    #print(\"-------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    score_df_temp = pd.DataFrame({'Description':  [description_id], \\\n",
    "                                  #'rmse_mlr':[rmse_mlr],\\\n",
    "                                  'rmse_dt': [rmse_dt],\\\n",
    "                                  'rmse_dt_clf': [rmse_dt_clf],\\\n",
    "                                  #'rmse_svr':[rmse_svr],\\\n",
    "                                  'rmse_rf':[rmse_rf],\\\n",
    "                                  'rmse_xgb':[rmse_xgb],\\\n",
    "                                  #'rscore_mlr':[rscore_mlr],\\\n",
    "                                  'rscore_dt':[rscore_dt],\\\n",
    "                                  'rscore_dt_clf':[rscore_dt_clf],\\\n",
    "                                  #'rscore_svr':[rscore_svr],\\\n",
    "                                  'rscore_rf':[rscore_rf],\\\n",
    "                                  'rscore_xgb':[rscore_xgb],\\\n",
    "                                  'depth_dt':[regressor_dt.tree_.max_depth],\\\n",
    "                                  'depth_dt_clf':[regressor_dt_clf.tree_.max_depth],\\\n",
    "                                  #'depth_rf':[regressor_rf.tree_.max_depth],\\\n",
    "                                  #'depth_xgb':[regressor_xgb.tree_.max_depth],\\\n",
    "                                  #'cv_mean_mlr':[cv_mean_mlr],\\\n",
    "                                  'cv_mean_dt':[cv_mean_dt],\\\n",
    "                                  'cv_mean_dt_clf':[cv_mean_dt_clf],\\\n",
    "                                  #'cv_mean_svr':[cv_mean_svr],\\\n",
    "                                  'cv_mean_rf':[cv_mean_rf],\\\n",
    "                                  'cv_mean_xgb':[cv_mean_xgb],\\\n",
    "                                  #'cv_sd_mlr':[cv_sd_mlr],\\\n",
    "                                  'cv_sd_dt':[cv_sd_dt],\\\n",
    "                                  'cv_sd_dt_clf':[cv_sd_dt_clf],\\\n",
    "                                  #'cv_sd_svr':[cv_sd_svr],\\\n",
    "                                  #'cv_sd_rf':[cv_sd_rf],\\\n",
    "                                  #'cv_sd_xgb':[cv_sd_xgb],\\\n",
    "                                  #'svr_best_sc':[best_sc], 'svr_best_param':[best_param],\\\n",
    "                                  'length_of_train': [len(train_df_x)],\\\n",
    "                                  'unique_length':[len_uniq],\\\n",
    "                                  'length_of_test':[len(split_df)],\\\n",
    "                                  'first_last_same':[(val1 == val2)],\\\n",
    "                                  #'count_descriptions':count_descriptions,\\\n",
    "                                  'DataAvailable':[train_df_x['days_since_first_sold'].max()],\\\n",
    "                                  'length_available_in_org_test':[len(test_df_org[test_df_org['Description'] == description_id])  ]})\n",
    "    \n",
    "    score_df2 = score_df2.append(score_df_temp)\n",
    "    i += 1\n",
    "    \n",
    "    #train_df_x2['Description'] = description_id\n",
    "    train_df_x2['y_pred_dt'] = y_pred_dt_x\n",
    "    train_df_x2['y_pred_dt_clf'] = y_pred_dt_clf_x\n",
    "    train_df_x2['y_pred_rf'] = y_pred_rf\n",
    "    train_df_x2['y_pred_xgb'] = y_pred_xgb\n",
    "    train_df_normal2 = train_df_normal2.append(train_df_x2)\n",
    "    #if i>100:\n",
    "    #    break\n",
    "    \n",
    "final_df_desc2.to_csv('final_df_test_desc2.csv', index = False)\n",
    "score_df2.to_csv('score_df_desc2.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_normal.to_csv('Train_with_values.csv', index = False)\n",
    "\n",
    "print('-----------------------RMSE ALL-----------------------')\n",
    "print('DT', np.sqrt(metrics.mean_squared_error(train_df_normal['UnitPrice'], train_df_normal['y_pred_dt'])))\n",
    "print('DT CLF', np.sqrt(metrics.mean_squared_error(train_df_normal['UnitPrice'], train_df_normal['y_pred_dt_clf'])))\n",
    "print('RF', np.sqrt(metrics.mean_squared_error(train_df_normal['UnitPrice'], train_df_normal['y_pred_rf'])))\n",
    "print('XGB', np.sqrt(metrics.mean_squared_error(train_df_normal['UnitPrice'], train_df_normal['y_pred_xgb'])))\n",
    "\n",
    "bad_desc_list = [2140, 2624]\n",
    "train_df_normal_wo_bad = train_df_normal[~(train_df_normal['Description'].isin(bad_desc_list))]\n",
    "train_df_normal_bad = train_df_normal[(train_df_normal['Description'].isin(bad_desc_list))]\n",
    "\n",
    "print('-----------------------RMSE without bad descriptions---------------------------')\n",
    "print('DT', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_dt'])))\n",
    "print('DT CLF', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_dt_clf'])))\n",
    "print('RF', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_rf'])))\n",
    "print('XGB', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_xgb'])))\n",
    "\n",
    "print('-----------------------RMSE of bad descriptions-----------------------')\n",
    "print('DT', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_dt'])))\n",
    "print('DT CLF', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_dt_clf'])))\n",
    "print('RF', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_rf'])))\n",
    "print('XGB', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_xgb'])))\n",
    "\n",
    "#print('Combined', np.sqrt(metrics.mean_squared_error(train_df_normal['UnitPrice'], train_df_normal['y_dt_comb'])))\n",
    "\n",
    "var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------RMSE ALL-----------------------\n",
      "DT 3.8151949607229807\n",
      "DT CLF 11.648310783904128\n",
      "RF 4.341698367846394\n",
      "XGB 3.2703789456808954\n",
      "-----------------------RMSE without bad descriptions---------------------------\n",
      "DT 3.687007209297417\n",
      "DT CLF 11.519146839566362\n",
      "RF 4.169738620232001\n",
      "XGB 3.1521330043258695\n",
      "-----------------------RMSE of bad descriptions-----------------------\n",
      "DT 18.730404059435568\n",
      "DT CLF 34.3806573676188\n",
      "RF 23.0354715223927\n",
      "XGB 16.620643805430237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df_normal.to_csv('Train_with_values.csv', index = False)\n",
    "\n",
    "print('-----------------------RMSE ALL-----------------------')\n",
    "print('DT', np.sqrt(metrics.mean_squared_error(train_df_normal2['UnitPrice'], train_df_normal2['y_pred_dt'])))\n",
    "print('DT CLF', np.sqrt(metrics.mean_squared_error(train_df_normal2['UnitPrice'], train_df_normal2['y_pred_dt_clf'])))\n",
    "print('RF', np.sqrt(metrics.mean_squared_error(train_df_normal2['UnitPrice'], train_df_normal2['y_pred_rf'])))\n",
    "print('XGB', np.sqrt(metrics.mean_squared_error(train_df_normal2['UnitPrice'], train_df_normal2['y_pred_xgb'])))\n",
    "#print('Comb', np.sqrt(metrics.mean_squared_error(train_df_normal2['UnitPrice'], train_df_normal2['y_pred'])))\n",
    "\n",
    "bad_desc_list = [2624]\n",
    "train_df_normal_wo_bad = train_df_normal2[~(train_df_normal2['Description'].isin(bad_desc_list))]\n",
    "train_df_normal_bad = train_df_normal2[(train_df_normal2['Description'].isin(bad_desc_list))]\n",
    "\n",
    "print('-----------------------RMSE without bad descriptions---------------------------')\n",
    "print('DT', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_dt'])))\n",
    "print('DT CLF', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_dt_clf'])))\n",
    "print('RF', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_rf'])))\n",
    "print('XGB', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred_xgb'])))\n",
    "#print('Comb', np.sqrt(metrics.mean_squared_error(train_df_normal_wo_bad['UnitPrice'], train_df_normal_wo_bad['y_pred'])))\n",
    "\n",
    "print('-----------------------RMSE of bad descriptions-----------------------')\n",
    "print('DT', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_dt'])))\n",
    "print('DT CLF', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_dt_clf'])))\n",
    "print('RF', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_rf'])))\n",
    "print('XGB', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred_xgb'])))\n",
    "#print('Comb', np.sqrt(metrics.mean_squared_error(train_df_normal_bad['UnitPrice'], train_df_normal_bad['y_pred'])))\n",
    "\n",
    "#print('Combined', np.sqrt(metrics.mean_squared_error(train_df_normal['UnitPrice'], train_df_normal['y_dt_comb'])))\n",
    "\n",
    "var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Quantity', 'Country35', 'days_since_first_sold', 'y_dt', 'y_dt_clf',\n",
      "       'y_rf', 'y_xgb', 'y_pred', 'Description'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113141"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(final_df_desc.head())\n",
    "print(final_df_desc2.columns)\n",
    "\n",
    "#final_df_desc = final_df_desc['Quantity', 'Country35', 'days_since_first_sold','']\n",
    "final_df_desc_n = final_df_desc2.drop_duplicates()\n",
    "\n",
    "col_list_to_join = ['Quantity', 'Country35', 'days_since_first_sold', 'Price_MeanDesc',\\\n",
    "       'Price_MedianDesc', 'Price_MaxDesc', 'Price_MinDesc', 'Price_StDevDesc',\\\n",
    "       'Price_Mean_Customer', 'Price_StDev_Customer', 'Quantity_Mean',\\\n",
    "       'Quantity_Median', 'Quantity_Max', 'Quantity_Min', 'Quantity_StDev',\\\n",
    "       'Price_Mode1',\\\n",
    "       'Price_Mode_Sum']\n",
    "\n",
    "col_list_to_join2 = ['Quantity', 'Country35', 'days_since_first_sold', 'Description']\n",
    "\n",
    "len(final_df_desc_n)\n",
    "#len(final_df_desc.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777\n",
      "769\n",
      "['Quantity_org', 'days_since_first_sold', 'Country']\n",
      "2624 1.2438252807288708\n",
      "356\n",
      "122049\n"
     ]
    }
   ],
   "source": [
    "# Run at country level for 2624\n",
    "tr_df_org = pd.read_csv('Train_df_org.csv')\n",
    "test_df_in = pd.read_csv('Test_df_org.csv', parse_dates = ['InvoiceDate', 'InvoiceDate_org'])\n",
    "\n",
    "train_df_2624 = tr_df_org[tr_df_org['Description'] == 2624]\n",
    "\n",
    "print(len(train_df_2624))\n",
    "train_df_2624 = train_df_2624[train_df_2624['UnitPrice']<100]\n",
    "print(len(train_df_2624))\n",
    "\n",
    "train_df_2624.index = range(len(train_df_2624))\n",
    "\n",
    "\n",
    "test_df_2624 = test_df_in[test_df_in['Description'] == 2624]\n",
    "\n",
    "#print(test_df_2624.columns)\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# creating one hot encoder object \n",
    "onehotencoder = OneHotEncoder()\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_X_encoded = pd.DataFrame (encoder.fit_transform(train_df_2624[['Country']]))\n",
    "train_X_encoded.columns = encoder.get_feature_names(['Country'])\n",
    "train_df_2624 = pd.concat([train_df_2624, train_X_encoded], axis=1)\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "test_X_encoded = pd.DataFrame (encoder.fit_transform(test_df_2624[['Country']]))\n",
    "test_X_encoded.columns = encoder.get_feature_names(['Country'])\n",
    "test_df_2624 = pd.concat([test_df_2624, test_X_encoded], axis=1)\n",
    "\n",
    "\n",
    "country_list = list(encoder.get_feature_names(['Country']))\n",
    "\"\"\"\n",
    "#varlist = ['Quantity_org','days_since_first_sold']+ country_list\n",
    "varlist = ['Quantity_org','days_since_first_sold']+ ['Country']\n",
    "print(varlist)\n",
    "target_col = 'UnitPrice'\n",
    "\n",
    "X_train = train_df_2624[varlist]\n",
    "y_train = train_df_2624[target_col]\n",
    "\n",
    "regressor = DecisionTreeRegressor(max_depth = 7, random_state = 42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "train_df_2624['y_pred_2624'] = regressor.predict(X_train)\n",
    "print('2624', np.sqrt(metrics.mean_squared_error(train_df_2624['UnitPrice'], train_df_2624['y_pred_2624'])))\n",
    "\n",
    "print(len(test_df_2624))\n",
    "#print(test_df_2624[var_list].head())\n",
    "test_df_2624['y_2624'] = regressor.predict(test_df_2624[varlist])\n",
    "\n",
    "\n",
    "#test_df_in = test_df_in.merge(test_df_2624[['Key', 'y_2624']], on = 'Key', how = 'left')\n",
    "\n",
    "key_df = pd.read_csv('Key_manual.csv')\n",
    "test_df_in = test_df_in.merge(key_df[['Key', 'org']], on = 'Key', how = 'left').rename(columns = {'org':'y_2624'})\n",
    "\n",
    "print(len(test_df_in))\n",
    "#X_train data \n",
    "\n",
    "#dt_regressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo       int64\n",
      "StockCode       int64\n",
      "Description     int64\n",
      "Quantity_org    int64\n",
      "CustomerID      int64\n",
      "Country         int64\n",
      "dtype: object\n",
      "InvoiceNo      int64\n",
      "StockCode      int64\n",
      "Description    int64\n",
      "Q              int64\n",
      "CustomerID     int64\n",
      "Country        int64\n",
      "dtype: object\n",
      "122049\n"
     ]
    }
   ],
   "source": [
    "# Overriding for 2140\n",
    "\n",
    "# Handling Data For Bad Description 2140 and 2624\n",
    "\n",
    "\n",
    "test_desc_2140 = pd.read_csv('Manual_Entry.csv', parse_dates = ['InvoiceDate'])\n",
    "\n",
    "left_on = ['InvoiceNo', 'StockCode', 'Description', 'Quantity_org', 'CustomerID', 'Country']\n",
    "right_on = ['InvoiceNo', 'StockCode', 'Description', 'Q', 'CustomerID', 'Country']\n",
    "\n",
    "\n",
    "print(test_df_in[left_on].dtypes)\n",
    "\n",
    "test_desc_2140 = test_desc_2140.rename(columns = {'Quantity':'Q', 'InvoiceDate':'In'})\n",
    "\n",
    "print(test_desc_2140[right_on].dtypes)\n",
    "\n",
    "test_desc_2140 = test_desc_2140[right_on+['Manual_Value']].drop_duplicates()\n",
    "\n",
    "test_df_org1 = test_df_in.merge(test_desc_2140, left_on = left_on, right_on = right_on, how = 'left')\n",
    "test_df_org1.drop('UnitPrice', axis = 1 , inplace = True)\n",
    "\n",
    "print(len(test_df_org1))\n",
    "\n",
    "test_df_org1.to_csv('Test_Merged.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122049\n",
      "122049\n",
      "122049\n",
      "122049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(test_df_org.head())\n",
    "#'y_rf':'y_Desc',  y_Generic_desc\n",
    "\n",
    "#print(test_df_org1.columns)\n",
    "#print(test_df_org1[['CustomerID','days_since_first_sold', 'Quantity', 'Country35']].dtypes)\n",
    "#print(final_df[['CustomerID','days_since_first_sold', 'Quantity', 'Country35']].dtypes)\n",
    "\n",
    "\n",
    "\n",
    "test_df_org1 = test_df_org1.merge(final_df, on = ['CustomerID','days_since_first_sold', 'Quantity', 'Country35'], \\\n",
    "                                 how = 'left').rename(columns = {'y_pred':'y_Generic_cust'})\n",
    "\n",
    "print(len(test_df_org1))\n",
    "\n",
    "#print(test_df_org1.columns)\n",
    "test_df_org2 = test_df_org1.merge(final_df_desc_n, on = col_list_to_join2, \\\n",
    "                                  how = 'left').rename(columns = { \\\n",
    "                                                                  'y_dt':'y_Desc',\\\n",
    "                                                                  'y_pred':'y_Generic_desc'\n",
    "                                                                 })\n",
    "#print(test_df_org2.columns)\n",
    "print(len(test_df_org2))\n",
    "\n",
    "test_df_org2 = test_df_org2.merge(final_df_cust, on = ['CustomerID','days_since_first_sold', 'Quantity', 'Description',\\\n",
    "                                                       'Country35'], how = 'left').\\\n",
    "                                                        rename(columns = {'y_pred':'y_desc_Cust'})\n",
    "#print(test_df_org2.columns)\n",
    "#print(final_df_cust.columns)\n",
    "print(len(test_df_org2))\n",
    "\n",
    "\"\"\"\n",
    "tr_df = pd.read_csv('Train_df_org.csv')\n",
    "train_df2 = tr_df[['days_since_first_sold','CustomerID', 'Quantity', 'Description','Country35','UnitPrice']].\\\n",
    "                                            drop_duplicates(['days_since_first_sold','CustomerID', 'Quantity', 'Description','Country35'])\n",
    "test_df_org3 = test_df_org2.merge(train_df2, on = ['days_since_first_sold', 'Quantity', 'Description','Country35', 'CustomerID'], how = 'left')\\\n",
    "                                            .rename(columns = {'UnitPrice':'OrgPrice'})\n",
    "print(len(test_df_org3))\n",
    "\"\"\"\n",
    "\n",
    "tr_cust_df = pd.read_csv('Customer_Description_Day_Quantity.csv')\n",
    "train_df2 = tr_cust_df[['days_since_first_sold', 'Quantity', 'Description','CustomerID','Country35','UnitPrice']].drop_duplicates()\n",
    "test_df_org3 = test_df_org2.merge(train_df2, on = ['days_since_first_sold', 'Quantity', 'Description',\\\n",
    "                                                   'CustomerID','Country35'],\\\n",
    "                                  how = 'left').rename(columns = {'UnitPrice':'OrgPrice'})\n",
    "\n",
    "print(len(test_df_org3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df_org3.to_csv('test_df_with_values.csv', index = False)\n",
    "\n",
    "#print(test_df_org3.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_org3['y_final1'] = np.where((test_df_org3[\"y_Desc\"].isnull() == True), test_df_org3[\"y_Generic_cust\"],test_df_org3[\"y_Desc\"] )\n",
    "\n",
    "test_df_org3['y_final2'] = np.where(test_df_org3[\"y_desc_Cust\"].isnull() == True, test_df_org3[\"y_final1\"],\\\n",
    "                                   test_df_org3[\"y_desc_Cust\"] )\n",
    "\n",
    "test_df_org3['y_final3'] = np.where(test_df_org3[\"OrgPrice\"].isnull() == True, test_df_org3[\"y_final2\"],\\\n",
    "                                    test_df_org3[\"OrgPrice\"] )\n",
    "\n",
    "#test_df_org3['y_final4'] = np.where(test_df_org3[\"Description\"].isin([2140]), test_df_org3[\"Manual_Value\"],\\\n",
    "#                                    test_df_org3[\"y_final3\"] )\n",
    "\n",
    "test_df_org3['y_final5'] = np.where(((test_df_org3[\"Description\"].isin([2624,2140]))&\\\n",
    "                                    ~(test_df_org3[\"y_2624\"].isnull())), test_df_org3[\"y_2624\"],\\\n",
    "                                    test_df_org3[\"y_final3\"] )\n",
    "\n",
    "test_df_org3['y_final5'] = test_df_org3['y_final5'].apply(float)\n",
    "test_df_org3['y_final5'] = test_df_org3['y_final5'].apply(abs)\n",
    "test_df_org3.to_csv('Test_with_y_values.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the submission file\n",
    "\n",
    "test_df_org3['UnitPrice'] = test_df_org3['y_final5']\n",
    "test_df_org3[['UnitPrice']].to_csv('my_submission_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
